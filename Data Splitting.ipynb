{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68efc173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ba10da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(562, 11)\n",
      "Index(['angina', 'DPQ020', 'OHQ850', 'OHQ835', 'SMQ020', 'WHD020', 'PAQ650',\n",
      "       'BPQ020', 'RIAGENDR', 'RIDAGEYR', 'DBQ700'],\n",
      "      dtype='object')\n",
      "     angina        DPQ020  OHQ850  OHQ835  SMQ020  WHD020  PAQ650  BPQ020  \\\n",
      "0     False  1.000000e+00     2.0     1.0     1.0   170.0     2.0     1.0   \n",
      "1      True  3.000000e+00     2.0     2.0     2.0   198.0     2.0     2.0   \n",
      "2      True  5.397605e-79     2.0     2.0     1.0   202.0     1.0     1.0   \n",
      "3     False  5.397605e-79     2.0     1.0     2.0   240.0     2.0     2.0   \n",
      "4      True  1.000000e+00     1.0     1.0     2.0   192.0     2.0     1.0   \n",
      "..      ...           ...     ...     ...     ...     ...     ...     ...   \n",
      "557    True  5.397605e-79     1.0     2.0     2.0   122.0     2.0     2.0   \n",
      "558   False  5.397605e-79     2.0     2.0     2.0   158.0     2.0     1.0   \n",
      "559    True  1.000000e+00     2.0     2.0     1.0   160.0     2.0     1.0   \n",
      "560    True  1.000000e+00     2.0     1.0     1.0   190.0     2.0     1.0   \n",
      "561   False  5.397605e-79     2.0     2.0     1.0   200.0     2.0     1.0   \n",
      "\n",
      "     RIAGENDR  RIDAGEYR  DBQ700  \n",
      "0         2.0      55.0     4.0  \n",
      "1         2.0      54.0     4.0  \n",
      "2         1.0      55.0     3.0  \n",
      "3         1.0      41.0     3.0  \n",
      "4         2.0      41.0     3.0  \n",
      "..        ...       ...     ...  \n",
      "557       2.0      64.0     2.0  \n",
      "558       2.0      75.0     3.0  \n",
      "559       1.0      68.0     3.0  \n",
      "560       2.0      56.0     4.0  \n",
      "561       1.0      80.0     3.0  \n",
      "\n",
      "[562 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv').drop(columns= ['Unnamed: 0', 'SEQN'])\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa1661",
   "metadata": {},
   "source": [
    "## Split dataset into X, y (and convert to NumPy Ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac53de12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(562, 10)\n",
      "Index(['DPQ020', 'OHQ850', 'OHQ835', 'SMQ020', 'WHD020', 'PAQ650', 'BPQ020',\n",
      "       'RIAGENDR', 'RIDAGEYR', 'DBQ700'],\n",
      "      dtype='object')\n",
      "(562,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split dataset into X, y\n",
    "Converted to NumPy Ndarray\n",
    "\"\"\"\n",
    "X = df.iloc[:, 1:]\n",
    "print(X.shape)\n",
    "print(X.columns)\n",
    "X = X.to_numpy()\n",
    "y = df['angina'].to_numpy()\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88c4f7",
   "metadata": {},
   "source": [
    "## Split total dataset dataset into 80:20 shuffled split (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "995b5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(449, 10)\n",
      "(113, 10)\n",
      "(449,)\n",
      "(113,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split total dataset into 80:20 split (train/test)\n",
    "Shuffled\n",
    "\"\"\"\n",
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(X, y, test_size=0.2, random_state=None, shuffle=True, stratify=None)\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "# print(y_train)\n",
    "# print(y_test)\n",
    "print(X_train_validation.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train_validation.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbf13e",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning (k-fold validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4bbe2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Used for hyperparameter tuning:\n",
    "Take training data and split into 75:25 splits for k-fold (use sklearn k-fold here) (train/ validation)\n",
    "4-5 folds \n",
    "Will use logistic regression in this example of code\n",
    "\"\"\"\n",
    "N_MODELS = 100\n",
    "alphas = np.logspace(-3, 6, N_MODELS)\n",
    "\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "accuracy_scores = np.zeros((N_MODELS,))\n",
    "f1_scores = np.zeros((N_MODELS,))\n",
    "ROC_scores = np.zeros((N_MODELS,))\n",
    " \n",
    "for i, alpha in enumerate(alphas):\n",
    "  average_accuracy = 0\n",
    "  average_f1_score = 0\n",
    "  average_roc_score = 0\n",
    "  \n",
    "  # run k_fold validation and sum performance metrics\n",
    "  for train_index, test_index in kf.split(X_train_validation):\n",
    "    \"\"\"\n",
    "      # print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "      TRAIN: 336 TEST: 113\n",
    "      TRAIN: 337 TEST: 112\n",
    "      TRAIN: 337 TEST: 112\n",
    "      TRAIN: 337 TEST: 112\n",
    "    \"\"\"\n",
    "    X_train, X_validation = X[train_index], X[test_index]\n",
    "    y_train, y_validation = y[train_index], y[test_index]\n",
    "    clf = LogisticRegression(C=alpha, max_iter=1000000).fit(X_train, y_train)\n",
    "    y_predictions = clf.predict(X_validation)\n",
    "    average_accuracy = average_accuracy + accuracy_score(y_validation, y_predictions)\n",
    "    average_f1_score = average_f1_score + f1_score(y_validation, y_predictions)\n",
    "    average_roc_score = average_roc_score + roc_auc_score(y_validation, y_predictions)\n",
    "    \n",
    "  # divide performance metrics by n_splits to get averages\n",
    "  accuracy_scores[i] = average_accuracy / n_splits\n",
    "  f1_scores[i] = average_f1_score / n_splits\n",
    "  ROC_scores[i] = average_roc_score / n_splits\n",
    "\n",
    "# print(accuracy_scores)\n",
    "# print(f1_scores)\n",
    "# print(ROC_scores)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d45640",
   "metadata": {},
   "source": [
    "## Evalute best hyperparameter (Needs to be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a67c772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5590826485461442 0.6257470261615841 0.5627155763539882\n",
      "[0.00187382] [0.00187382] [0.00187382]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evalute best hyperparameter\n",
    "\"\"\"\n",
    "alpha_with_max_accuracy = alphas[np.where(accuracy_scores == max(accuracy_scores))]\n",
    "alpha_with_max_f1_score = alphas[np.where(f1_scores == max(f1_scores))]\n",
    "alpha_with_max_ROC_score = alphas[np.where(ROC_scores == max(ROC_scores))]\n",
    "print(max(accuracy_scores), max(f1_scores), max(ROC_scores))\n",
    "print(alpha_with_max_accuracy, alpha_with_max_f1_score, alpha_with_max_ROC_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1130d200",
   "metadata": {},
   "source": [
    "## Evalute model on test set using selected hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cb297f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5663716814159292 0.5585585585585586 0.5682674199623352\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evalute model on test set using selected hyperparameter\n",
    "\"\"\"\n",
    "alpha = 0.00187382\n",
    "clf = LogisticRegression(C=0.00187382, max_iter=1000000).fit(X_train_validation, y_train_validation)\n",
    "y_predictions = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predictions)\n",
    "f1 = f1_score(y_test, y_predictions)\n",
    "roc_score = roc_auc_score(y_test, y_predictions)\n",
    "print(accuracy, f1, roc_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4357b58558cb56728375674edd814cfb65f54b921a7d684fdf91b4027b79620"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
